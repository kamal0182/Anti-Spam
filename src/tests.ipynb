{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04a1af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d71973f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da8989ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DataSet_Emails.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07a283bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  message_id                                               text  \\\n",
      "0           0       33214  any software just for 15 $ - 99 $ understandin...   \n",
      "1           1       11929  perspective on ferc regulatory action client c...   \n",
      "2           2       19784  wanted to try ci 4 lis but thought it was way ...   \n",
      "3           3        2209  enron / hpl actuals for december 11 , 2000 tec...   \n",
      "4           4       15880  looking for cheap high - quality software ? ro...   \n",
      "\n",
      "   label label_text                                            subject  \\\n",
      "0      1       spam                  any software just for 15 $ - 99 $   \n",
      "1      0        ham  perspective on ferc regulatory action client c...   \n",
      "2      1       spam  wanted to try ci 4 lis but thought it was way ...   \n",
      "3      0        ham         enron / hpl actuals for december 11 , 2000   \n",
      "4      1       spam  looking for cheap high - quality software ? ro...   \n",
      "\n",
      "                                             message        date  \n",
      "0  understanding oem software\\nlead me not into t...  2005-06-18  \n",
      "1  19 th , 2 : 00 pm edt\\nperspective on ferc reg...  2001-06-19  \n",
      "2  viagra at $ 1 . 12 per dose\\nready to boost yo...  2004-09-11  \n",
      "3  teco tap 30 . 000 / enron ; 120 . 000 / hpl ga...  2000-12-12  \n",
      "4  water past also , burn , course . gave country...  2005-02-13  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d544597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31716 entries, 0 to 31715\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  31716 non-null  int64 \n",
      " 1   message_id  31716 non-null  int64 \n",
      " 2   text        31665 non-null  object\n",
      " 3   label       31716 non-null  int64 \n",
      " 4   label_text  31716 non-null  object\n",
      " 5   subject     31442 non-null  object\n",
      " 6   message     31371 non-null  object\n",
      " 7   date        31716 non-null  object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 1.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4908904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0      0\n",
      "message_id      0\n",
      "text           51\n",
      "label           0\n",
      "label_text      0\n",
      "subject       274\n",
      "message       345\n",
      "date            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "181b61c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b1a134a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    16163\n",
      "0    15553\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e82c8117",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Visualiser la distribution\n",
    "# df['label'].value_counts().plot(kind='bar', color=['green', 'red'])\n",
    "# plt.title('Distribution des emails (Ham vs Spam)')\n",
    "# plt.xlabel('Type')\n",
    "# plt.ylabel('Nombre')\n",
    "# plt.xticks(rotation=0)\n",
    "# plt.savefig('DistributionDesEmails(HamVSSpam)')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa56c514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a65e1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_text = \" \".join(df[df['label_text'] == 'spam']['text'].astype(str))\n",
    "ham_text = \" \".join(df[df['label_text'] == 'ham']['text'].astype(str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b80b703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wc_spam = WordCloud(width=800, height=400, background_color='white').generate(spam_text)\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.imshow(wc_spam)\n",
    "# plt.axis('off')\n",
    "# plt.title(\"Mots fréquents dans les spams\")\n",
    "# plt.savefig('MotsFréquentsDansLesSpams')\n",
    "# plt.close()\n",
    "\n",
    "# wc_ham = WordCloud(width=800, height=400, background_color='white').generate(ham_text)\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.imshow(wc_ham)\n",
    "# plt.axis('off')\n",
    "# plt.title(\"Mots fréquents dans les hams\")\n",
    "# plt.savefig('MotsFréquentsDansLesHams')\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2765f302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        any software just for 15 $ - 99 $ understandin...\n",
       "1        perspective on ferc regulatory action client c...\n",
       "2        wanted to try ci 4 lis but thought it was way ...\n",
       "3        enron / hpl actuals for december 11 , 2000 tec...\n",
       "4        looking for cheap high - quality software ? ro...\n",
       "                               ...                        \n",
       "31711    credit netco start up plan louise ,\\nattached ...\n",
       "31712    everything you are looking for hello , visit o...\n",
       "31713    start date : 2 / 5 / 02 ; hourahead hour : 18 ...\n",
       "31714    corhshucker daren - - - -\\nthe invoices are be...\n",
       "31715    re : prosym license hi karolina ,\\nthe last wo...\n",
       "Name: text, Length: 31716, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6202dfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7ce3def",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ebf08d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text'].str.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2362ada9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5ef6133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d91e533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8f6fc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\abirm/nltk_data', 'c:\\\\Users\\\\abirm\\\\Projects\\\\SpamShieldAI\\\\venv\\\\nltk_data', 'c:\\\\Users\\\\abirm\\\\Projects\\\\SpamShieldAI\\\\venv\\\\share\\\\nltk_data', 'c:\\\\Users\\\\abirm\\\\Projects\\\\SpamShieldAI\\\\venv\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\abirm\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data', 'c:\\\\Users\\\\abirm\\\\Projects\\\\SpamShieldAI\\\\nltk_data']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.data.path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5053a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     c:\\Users\\abirm\\Projects\\SpamShieldAI\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     c:\\Users\\abirm\\Projects\\SpamShieldAI\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "# Créer un dossier nltk_data dans votre venv\n",
    "nltk_data_dir = os.path.join(os.getcwd(), 'nltk_data')\n",
    "os.makedirs(nltk_data_dir, exist_ok=True)\n",
    "\n",
    "# Ajouter ce chemin\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "# Télécharger punkt dans ce dossier\n",
    "nltk.download('punkt', download_dir=nltk_data_dir)\n",
    "nltk.download('punkt_tab', download_dir=nltk_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e5326ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     c:\\Users\\abirm\\Projects\\SpamShieldAI\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords', download_dir=nltk_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d41a5a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df['text'] = df['text'].astype(str).apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "97a8dd14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['any', 'software', 'just', 'for', '15', '$', ...\n",
       "1    ['perspective', 'on', 'ferc', 'regulatory', 'a...\n",
       "2    ['wanted', 'to', 'try', 'ci', '4', 'lis', 'but...\n",
       "3    ['enron', '/', 'hpl', 'actuals', 'for', 'decem...\n",
       "4    ['looking', 'for', 'cheap', 'high', '-', 'qual...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].astype(str).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "55de2d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b8ab5a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda tokens: [t for t in tokens if t.lower() not in stop_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8fa06768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df['text'] = df['text'].apply(\n",
    "    lambda tokens: [t for t in tokens if re.match(r'^[A-Za-z0-9]+$', t)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "613975d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e7f4dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(\n",
    "    lambda tokens: [stemmer.stem(t) for t in tokens]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd276121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['softwar', '15', '99', 'understand', 'oem', '...\n",
       "1    ['perspect', 'ferc', 'regulatori', 'action', '...\n",
       "2    ['want', 'tri', 'ci', '4', 'li', 'thought', 'w...\n",
       "3    ['enron', 'hpl', 'actual', 'decemb', '11', '20...\n",
       "4    ['look', 'cheap', 'high', 'qualiti', 'softwar'...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].astype(str).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52f2af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=lambda x: x,  \n",
    "    preprocessor=lambda x: x, \n",
    "    token_pattern=None        \n",
    ")\n",
    "\n",
    "X = tfidf.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "05e0c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "97cfc7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, df['label'], test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c1fbc9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70f2f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=300),\n",
    "    \"SVM (Linear)\": SVC(kernel=\"linear\"),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8b35aec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== \n",
      " model Logistic Regression\n",
      "Accuracy: 0.9851571135322912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98      3120\n",
      "           1       0.97      1.00      0.99      3213\n",
      "\n",
      "    accuracy                           0.99      6333\n",
      "   macro avg       0.99      0.98      0.99      6333\n",
      "weighted avg       0.99      0.99      0.99      6333\n",
      "\n",
      "=================== \n",
      " model SVM (Linear)\n",
      "Accuracy: 0.9902100110532134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      3120\n",
      "           1       0.98      1.00      0.99      3213\n",
      "\n",
      "    accuracy                           0.99      6333\n",
      "   macro avg       0.99      0.99      0.99      6333\n",
      "weighted avg       0.99      0.99      0.99      6333\n",
      "\n",
      "=================== \n",
      " model Naive Bayes\n",
      "Accuracy: 0.9846834043897047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3120\n",
      "           1       0.98      0.99      0.98      3213\n",
      "\n",
      "    accuracy                           0.98      6333\n",
      "   macro avg       0.98      0.98      0.98      6333\n",
      "weighted avg       0.98      0.98      0.98      6333\n",
      "\n",
      "=================== \n",
      " model Random Forest\n",
      "Accuracy: 0.987841465340281\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3120\n",
      "           1       0.98      0.99      0.99      3213\n",
      "\n",
      "    accuracy                           0.99      6333\n",
      "   macro avg       0.99      0.99      0.99      6333\n",
      "weighted avg       0.99      0.99      0.99      6333\n",
      "\n",
      "=================== \n",
      " model Gradient Boosting\n",
      "Accuracy: 0.9502605400284225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      3120\n",
      "           1       0.92      0.99      0.95      3213\n",
      "\n",
      "    accuracy                           0.95      6333\n",
      "   macro avg       0.95      0.95      0.95      6333\n",
      "weighted avg       0.95      0.95      0.95      6333\n",
      "\n",
      "=================== \n",
      " model KNN\n",
      "Accuracy: 0.9714195483972841\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3120\n",
      "           1       0.97      0.97      0.97      3213\n",
      "\n",
      "    accuracy                           0.97      6333\n",
      "   macro avg       0.97      0.97      0.97      6333\n",
      "weighted avg       0.97      0.97      0.97      6333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    print(f'=================== \\n model {name}')\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "    print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fcf73b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = models[\"SVM (Linear)\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5266ad85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.pkl']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(svm_model, \"svm_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
